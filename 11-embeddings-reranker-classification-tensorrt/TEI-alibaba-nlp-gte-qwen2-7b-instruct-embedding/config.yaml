base_image:
  image: baseten/text-embeddings-inference-mirror:hopper-1.6
docker_server:
  liveness_endpoint: /health
  predict_endpoint: /v1/embeddings
  readiness_endpoint: /health
  server_port: 7997
  start_command: bash -c "truss-transfer-cli && text-embeddings-router --port 7997
    --model-id /app/model_cache/cached_model --max-client-batch-size 128 --max-concurrent-requests
    128 --max-batch-tokens 16384 --auto-truncate"
model_cache:
- repo_id: Alibaba-NLP/gte-Qwen2-7B-instruct
  revision: main
  use_volume: true
  volume_folder: cached_model
model_metadata:
  example_model_input:
    encoding_format: float
    input: text string
    model: model
model_name: TEI-alibaba-nlp-gte-qwen2-7b-instruct-embedding-truss-example
python_version: py39
resources:
  accelerator: H100_40GB
  cpu: '1'
  memory: 2Gi
  use_gpu: true
runtime:
  predict_concurrency: 32
