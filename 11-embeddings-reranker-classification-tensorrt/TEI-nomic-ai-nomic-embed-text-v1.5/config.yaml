base_image:
  image: baseten/text-embeddings-inference-mirror:86-1.6
build_commands:
- 'git clone https://huggingface.co/nomic-ai/nomic-embed-text-v1.5 /data/local-model
  # optional step to download the weights of the model into the image, otherwise specify
  `--model-id nomic-ai/nomic-embed-text-v1.5` directly in the section `start_command`
  below -and remove the build_commands section.'
- echo 'Model downloaded via git clone'
docker_server:
  liveness_endpoint: /health
  predict_endpoint: /v1/embeddings
  readiness_endpoint: /health
  server_port: 7997
  start_command: text-embeddings-router --port 7997 --model-id /data/local-model --max-client-batch-size
    128 --max-concurrent-requests 40 --max-batch-tokens 16384
environment_variables: {}
external_package_dirs: []
model_metadata:
  example_model_input:
    encoding_format: float
    input: text string
    model: model
model_name: TEI-nomic-ai-nomic-embed-text-v1.5-truss-example
python_version: py39
requirements: []
resources:
  accelerator: A10G
  cpu: '1'
  memory: 2Gi
  use_gpu: true
runtime:
  predict_concurrency: 40
secrets: {}
system_packages: []
