build_commands: []
environment_variables:
  ENABLE_EXECUTOR_API: 1
external_package_dirs: []
model_metadata:
  example_model_input:
    max_tokens: 512
    messages:
      - content: Tell me everything you know about optimized inference.
        role: user
    stream: true
    temperature: 0.5
  tags:
    - openai-compatible
model_name: Briton-meta-llama-llama-3.1-405b-fp8-truss-example
python_version: py39
requirements: []
resources:
  accelerator: H100:8
  cpu: "1"
  memory: 10Gi
  use_gpu: true
secrets:
  hf_access_token: null
system_packages: []
trt_llm:
  build:
    base_model: llama
    checkpoint_repository:
      # presigned url from: https://us-east-2.console.aws.amazon.com/s3/buckets/mp-model-weights-public?bucketType=general&region=us-east-2&tab=objects#
      # feel free to reach out to us if you need access to this bucket
      repo: https://mp-model-weights-public.s3.us-east-2.amazonaws.com/llama-405b-tp8-fp8kv-tllm.tar?response-content-disposition=inline&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEJL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMiJGMEQCIDY7xuaSvn%2Fyu3YV5ekwZ5HiNUTMzSmN65vsbwVhaaiZAiA8XTdjL80hY9LU6jdnHIzG8%2FD%2F%2FibPCl5wCsMSbTffiSrcAwj7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAIaDDgzNjg4NTU1NzY2NSIMWhIK3G3WJ5dJHmmEKrADFM9Q44q1LX%2Bj5lebD8pxezX4%2FRV9JPzrQueNhfCgFulpD6BPLvN8yaI7jDBenHPdvh6UgIYM%2F2XJ%2B0TQUdQoNrnVm%2F7UqqWzf3TAYlgmkfeSeO6VXDIr3lrxSIiM4p0hP3dN9WNrgRwjvCGHtJJV5T8kjM4ow7cs%2FJeWiwUhmySOkFLdBTgC8x0uIPWoL30itt30wseMfskJkfbS7yluAPRAocVsXAEJPqPQ%2FuRoBvy7TFzOBDBp%2B2KRZbsT2usTnd%2BeSZiNNbyqxTLuDF4IQloZRVdnWuvYIEaEsY7NTWFbd7Wtcdk1Wcw5kSzRa%2BOpE4khjLod%2Bqk7NTM3q6TjVxBeR%2BhIDynV%2Bm3AHTt8AF7PyjW%2BzvAH2mkEs1LtUr5rXoevvaIX2a2i75yudjmKJZCv7ZrEYks7lY4lckjIMq30GMkBQKAVjJ0VO7nnWgmihqQJNU96nr92X6EXKZs4DeyriWpJ2wrEwAVJ6kLG1CxfZKJoa1CXHP0pda5FPB%2FHDxfI91C1lHYbrJcmlg%2Be%2B9VJQN8DelWNKkfnjqyAxHuLpF3Ou%2Foqy3577649K4egMPr0vL8GOrgCrOkASDF0UUri2k%2BhFiuio76zNGL%2BbgpifiHSD34%2FgBfKV47r9yxJLYsA8uquuULefF50zvrIRQaXwQCruAADiKuumWsEWK630DKYv%2BMurZRyCyt94mLH%2FsBQqL5mTXUeRi73Tz4%2F%2BOmQ3TP0QYOh7JV%2FPw1rCHQqW%2BvdsEUw1zhOPhjTw3Te9QUKA%2FLc5aO%2FHo3sCYAl%2FigrDEFprzpaMV%2FNfJmJ%2FDxXj%2F%2FaxwNASU2kYuWly3hKJjJogoJfJIpf2LVI5lUScGq8Dld47WZGbdwH4KNoo8rNRX1xvAXPxGOlHGmtSK8jrWn9y53vTe3YyZaCVm4Tv6rA0XhZoSmManhNL9TGCAtEbOWOgcIBaO1HcuFq9Mr6s09uX9N0arnRkkDbVf6djybmFWQkMJncH3yvXvG43j2H&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIA4FWSEGGQ3O26MOZ5%2F20250404%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20250404T014921Z&X-Amz-Expires=43200&X-Amz-SignedHeaders=host&X-Amz-Signature=903bf4a4772826a97b3e20cca737d5a1d90edd715d997743b8de26cca74e706d
      source: REMOTE_URL
    max_seq_len: 131072
    plugin_configuration:
      use_fp8_context_fmha: true
    quantization_type: fp8_kv
    tensor_parallel_count: 8
  runtime:
    enable_chunked_context: true
